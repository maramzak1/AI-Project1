{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd8be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Chemins des fichiers\n",
    "CSV_PATH = r\"C:\\Users\\maram\\Desktop\\gen\\data_text\\Animal disease spreadsheet - Sheet1.csv\"\n",
    "PDF_PATH = r\"C:\\Users\\maram\\Desktop\\gen\\data_text\\TableauMaladiesChienASSURVETO.pdf\"\n",
    "VECTOR_STORE_PATH = \"./vector_store\"\n",
    "\n",
    "# Configuration du modèle\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "LLM_MODEL = \"llama3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd55e1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "\n",
    "def load_and_process_data():\n",
    "    # Chargement CSV\n",
    "    data = pd.read_csv(CSV_PATH)\n",
    "    data.drop(columns=[\"Treatment\", \"Advice/ Prevention\"], inplace=True)\n",
    "    \n",
    "    # Chargement PDF\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    pdf_pages = loader.load()\n",
    "     # Découpage des textes\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    \n",
    "    # Combinaison des données\n",
    "    documents = []\n",
    "    \n",
    "    # Ajout des données CSV\n",
    "    for _, row in data.iterrows():\n",
    "        content = f\"Symptoms: {row['Symptoms']}\\nDescription: {row['Description']}\"\n",
    "        documents.append(Document(\n",
    "            page_content=content,\n",
    "            metadata={\"source\": \"csv\", \"disease\": row['Recognition']}\n",
    "        ))\n",
    "        documents.extend(text_splitter.split_documents(pdf_pages))\n",
    "    \n",
    "    return documents\n",
    "documents = load_and_process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26615bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maram\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def create_vector_store(docs, force_recreate=False):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "    \n",
    "    if not force_recreate and os.path.exists(VECTOR_STORE_PATH):\n",
    "        # Modification ici: ajout du paramètre allow_dangerous_deserialization\n",
    "        return FAISS.load_local(\n",
    "            VECTOR_STORE_PATH,\n",
    "            embeddings,\n",
    "            allow_dangerous_deserialization=True  # Sécurisé car c'est vous qui avez créé le fichier\n",
    "        )\n",
    "    vector_store = FAISS.from_documents(docs, embeddings)\n",
    "    vector_store.save_local(VECTOR_STORE_PATH)\n",
    "    return vector_store\n",
    "\n",
    "vector_store = create_vector_store(documents)\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0a58097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur Ollama: Error: listen tcp 127.0.0.1:11434: bind: Only one usage of each socket address (protocol/network address/port) is normally permitted.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maram\\AppData\\Local\\Temp\\ipykernel_1628\\1116765613.py:14: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=LLM_MODEL)\n"
     ]
    }
   ],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"[SYSTEM] Vous êtes un assistant vétérinaire expert. Répondez en français.\n",
    "[CONTEXTE] {context}\n",
    "[QUESTION] {question}\n",
    "[INSTRUCTIONS]\n",
    "1. Analysez les symptômes\n",
    "2. Proposez un diagnostic probable\n",
    "3. Indiquez le niveau d'urgence\n",
    "4. Donnez des conseils de premiers soins\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=PROMPT_TEMPLATE,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "llm = Ollama(model=LLM_MODEL)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    result = subprocess.run([\"ollama\", \"serve\"], check=True, capture_output=True)\n",
    "    print(\"Ollama serveur fonctionne correctement\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Erreur Ollama: {e.stderr.decode()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fb1c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "import torch\n",
    "def setup_llm():\n",
    "    try:\n",
    "        # Essayer d'abord avec CUDA si disponible\n",
    "        if torch.cuda.is_available():\n",
    "            llm = Ollama(\n",
    "                model=\"llama3\",\n",
    "                temperature=0.7,\n",
    "                timeout=300\n",
    "            )\n",
    "            # Test de connexion\n",
    "            llm.invoke(\"Test\")\n",
    "            return llm\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec CUDA: {e}. Basculer sur CPU...\")\n",
    "   \n",
    "    # Fallback sur CPU\n",
    "    return Ollama(\n",
    "        model=\"llama3\",\n",
    "        temperature=0.7,\n",
    "        timeout=300\n",
    "    )\n",
    "llm = setup_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb87f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "import os\n",
    "\n",
    "# Forcer l'utilisation du CPU au niveau système\n",
    "os.environ[\"OLLAMA_NO_CUDA\"] = \"1\"\n",
    "\n",
    "llm = Ollama(\n",
    "    model=\"llama3:instruct\", \n",
    "    temperature=0.7,\n",
    "    timeout=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4325d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maram\\AppData\\Local\\Temp\\ipykernel_1628\\1691426927.py:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse:\n",
      "Bonjour, je suis ravi de vous aider à comprendre la situation de votre chien.\n",
      "\n",
      "**Analyse des symptômes**\n",
      "Votre chien vomit et a la diarrhée, ce qui suggère une maladie gastro-entérite. Il est important de noter que les deux formes de cette maladie, gastrique et myocardique, peuvent être graves si elles ne sont pas traitées à temps.\n",
      "\n",
      "**Diagnostic probable**\n",
      "La forme gastrique de la maladie peut être suspectée en raison des vomissements et de la diarrhée. Cependant, il est important de consulter un vétérinaire pour obtenir un diagnostic définitif et exclure d'autres causes possibles de ces symptômes.\n",
      "\n",
      "**Niveau d'urgence**\n",
      "La situation est considérablement urgente car si votre chien perd trop d'eau et d'électrolytes en raison des diarrhées, il peut entrer en choc circulatoire. Il est donc essentiel de prendre des mesures pour équilibrer les pertes.\n",
      "\n",
      "**Conseils de premiers soins**\n",
      "Voici quelques conseils que je vous recommande :\n",
      "\n",
      "* Faites sortir votre chien de la maison pour éviter tout risque de contamination.\n",
      "* Assurez-vous qu'il a accès à suffisamment d'eau et à un aliment sec.\n",
      "* Essayez de maintenir une hygiène rigoureuse en évitant tout contact direct avec les selles ou les vomissements.\n",
      "* Si votre chien continue à vomir et à avoir la diarrhée, il est essentiel de consulter un vétérinaire le plus rapidement possible.\n",
      "\n",
      "En résumé, il est crucial de consulter un vétérinaire pour obtenir un diagnostic définitif et un traitement approprié. J'espère que votre chien récupèrera bientôt.\n",
      "\n",
      "Sources utilisées:\n",
      "\n",
      "- Source: C:/Users/maram/Desktop/gen/data_text\\TableauMaladiesChienASSURVETO.pdf\n",
      "  Extrait: oculaires et nerveux.\n",
      "Il n’existe pas de \n",
      "traitement à ce jour. Le \n",
      "vétérinaire peut \n",
      "administrer un traitement \n",
      "symptomatique mais la \n",
      "mort se produit le plus \n",
      "souvent.\n",
      "Une hygiène rigoureuse. \n",
      "La va...\n",
      "\n",
      "- Source: C:/Users/maram/Desktop/gen/data_text\\TableauMaladiesChienASSURVETO.pdf\n",
      "  Extrait: celui la rougeole. Sa \n",
      "contagion se fait de chien \n",
      "à chien (léchage, contact \n",
      "nez à nez).\n",
      "Symptômes\n",
      "L’isolement de l’animal \n",
      "infecté.\n",
      "Le traitement spécifique \n",
      "est la sérothérapie, qui \n",
      "reste efficace...\n",
      "\n",
      "- Source: C:/Users/maram/Desktop/gen/data_text\\TableauMaladiesChienASSURVETO.pdf\n",
      "  Extrait: Plaques enflammées, \n",
      "purulentes et avec \n",
      "croutes. Elles entraînent \n",
      "la chutte des poils.\n",
      "Il est possible de vacciner \n",
      "le chien avant le début \n",
      "des symptômes.\n",
      "Après, il n’existe pas de \n",
      "traitement de l...\n",
      "Réponse:\n",
      "Bonjour, je suis ravi de vous aider ! Pour analyser les symptômes de votre chien, je vais suivre l'étape 1 des instructions.\n",
      "\n",
      "**Symptômes**\n",
      "\n",
      "* Le chien secoue-t-il plus la tête et/ou se gratte-t-il les oreilles ? Oui (9)\n",
      "* La tête ou les oreilles présentent-elles des parties enflées ? Non\n",
      "* Voit-on des blessures ? Non\n",
      "* Le port de tête de l'animal est-il anormal (p. ex. tête inclinée) ? Non\n",
      "\n",
      "**Voies respiratoires**\n",
      "\n",
      "* La respiration est-elle difficile ou plus rapide ? Oui (5)\n",
      "* Le chien halète-t-il plus ? Oui\n",
      "* Entend-on comme un sifflement ou un râle ? Oui\n",
      "* L'animal tousse-t-il de façon répétée ? Non\n",
      "\n",
      "**Peau**\n",
      "\n",
      "* Y a-t-il des blessures, croûtes ou autres altérations de la peau ? Non (9)\n",
      "\n",
      "En analyse, je note que votre chien présente une respiration difficile et rapide, accompagnée d'un halètement et d'un sifflement. Ceci laisse penser à une possible infection pulmonaire.\n",
      "\n",
      "**Diagnostic probable**\n",
      "\n",
      "Je pense que votre chien pourrait être atteint d'une pneumonie (infection des poumons). Il est possible que cela soit causé par un agent pathogène, telle que la bordoneuse canine ou la peste canicole.\n",
      "\n",
      "**Niveau d'urgence**\n",
      "\n",
      "Le niveau d'urgence est élevé. Il est important de consulter immédiatement un vétérinaire pour obtenir un diagnostic et un traitement appropriés.\n",
      "\n",
      "**Conseils de premiers soins**\n",
      "\n",
      "Avant de consulter le vétérinaire, il est essentiel de maintenir votre chien dans une pièce sombre, calme et au frais. Il est également important de ne pas donner à votre chien de la nourriture ou de l'eau trop froide, car cela pourrait aggraver sa situation. Il est recommandé de réduire les activités physiques de votre chien pour éviter de l'épuiser.\n",
      "\n",
      "Il est important de rappeler que ces conseils sont only des premiers soins et ne peuvent pas remplacer une consultation avec un vétérinaire. Il est crucial de consulter un professionnel pour obtenir un diagnostic et un traitement appropriés.\n",
      "\n",
      "Sources utilisées:\n",
      "\n",
      "- Source: C:/Users/maram/Desktop/gen/data_text\\mb_signes_maladie.pdf\n",
      "  Extrait: ou des croûtes?\n",
      " 9 L’animal secoue-t-il plus la tête et/ou se gratte-t-il les oreilles?\n",
      " 9 La tête ou les oreilles présentent-elles des parties enflées?\n",
      " 9 Voit-on des blessures?\n",
      " \u001d Le port de tête de...\n",
      "\n",
      "- Source: C:/Users/maram/Desktop/gen/data_text\\mb_signes_maladie.pdf\n",
      "  Extrait: 9 Y a-t-il des blessures, croûtes ou autres altérations de la peau?\n",
      " 3 Les lézards ou les serpents se brûlent fréquemment. Il faut donc veiller à ce que les \n",
      "animaux ne soient pas en contact direct av...\n",
      "\n",
      "- Source: C:/Users/maram/Desktop/gen/data_text\\mb_signes_maladie.pdf\n",
      "  Extrait: chez ces animaux des signes de maladie, une visite chez le vétérinaire est généralement, dans ce \n",
      "cas, inévitable parce que la maladie est souvent déjà bien avancée. \n",
      "Avant de se rendre chez le vétéri...\n"
     ]
    }
   ],
   "source": [
    "def veterinary_chatbot(question):\n",
    "    try:\n",
    "        result = qa_chain({\"query\": question})\n",
    "        \n",
    "        print(\"Réponse:\")\n",
    "        print(result[\"result\"])\n",
    "        \n",
    "        print(\"\\nSources utilisées:\")\n",
    "        for doc in result[\"source_documents\"]:\n",
    "            print(f\"\\n- Source: {doc.metadata.get('source', 'inconnu')}\")\n",
    "            if 'disease' in doc.metadata:\n",
    "                print(f\"  Maladie: {doc.metadata['disease']}\")\n",
    "            print(f\"  Extrait: {doc.page_content[:200]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la génération de la réponse: {e}\")\n",
    "        print(\"Veuillez vérifier que le serveur Ollama est bien lancé et que le modèle est téléchargé.\")\n",
    "\n",
    "# Test avec gestion d'erreur\n",
    "try:\n",
    "    veterinary_chatbot(\"Mon chien vomit et a la diarrhée\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur critique: {e}\")\n",
    "def veterinary_chatbot(question):\n",
    "    result = qa_chain({\"query\": question})\n",
    "    \n",
    "    print(\"Réponse:\")\n",
    "    print(result[\"result\"])\n",
    "    \n",
    "    print(\"\\nSources utilisées:\")\n",
    "    for doc in result[\"source_documents\"]:\n",
    "        print(f\"\\n- Source: {doc.metadata.get('source', 'inconnu')}\")\n",
    "        if 'disease' in doc.metadata:\n",
    "            print(f\"  Maladie: {doc.metadata['disease']}\")\n",
    "        print(f\"  Extrait: {doc.page_content[:200]}...\")\n",
    "\n",
    "# Test\n",
    "veterinary_chatbot(\"Mon chien cri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ce098c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modèle, embeddings, base vectorielle et chaîne QA sauvegardés.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Sauvegarde de la QA chain (sans le modèle car il est réinstancié à chaque fois dans l'API)\n",
    "with open(\"qa_chain.pkl\", \"wb\") as f:\n",
    "    pickle.dump(qa_chain, f)\n",
    "\n",
    "print(\"✅ Modèle, embeddings, base vectorielle et chaîne QA sauvegardés.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
