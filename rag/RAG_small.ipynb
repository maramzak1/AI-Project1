{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# **1. Imports Section**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Main Script ---\n",
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from transformers import pipeline\n",
        "from langchain_core.documents import Document\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_DIR = \"rag_data\"\n",
        "PDF_DIRS = [\"research_papers\", \"clinical_studies\", \"fda_reports\"]\n",
        "HTML_DIRS = [\"kennel_clubs\", \"vet_associations\", \"breeder_forums\"]\n",
        "STRUCTURED_DATA_PATH = os.path.join(DATA_DIR, \"structured\", \"breed_health_data.xlsx\")\n",
        "VECTOR_DB_PATH = os.path.join(DATA_DIR, \"unstructured\", \"vector_db\")\n",
        "\n",
        "# --- Fixed Document Loading ---\n",
        "def load_documents():\n",
        "    docs = []\n",
        "    print(\"\\n[Document Loading Progress]\")\n",
        "    \n",
        "    # 1. Verify directory structure exists\n",
        "    print(\"\\nüîç Verifying directory structure...\")\n",
        "    required_dirs = {\n",
        "        \"PDFs\": [os.path.join(DATA_DIR, \"unstructured\", \"pdfs\", d) for d in PDF_DIRS],\n",
        "        \"HTML\": [os.path.join(DATA_DIR, \"unstructured\", \"web_articles\", d) for d in HTML_DIRS],\n",
        "        \"Structured\": [os.path.dirname(STRUCTURED_DATA_PATH)]\n",
        "    }\n",
        "    \n",
        "    # Check and report missing directories\n",
        "    for data_type, dirs in required_dirs.items():\n",
        "        missing = [d for d in dirs if not os.path.exists(d)]\n",
        "        if missing:\n",
        "            print(f\"‚ö†Ô∏è Missing {data_type} directories: {missing}\")\n",
        "        else:\n",
        "            print(f\"‚úì All {data_type} directories present\")\n",
        "\n",
        "    # 2. Load structured data from Excel\n",
        "    print(\"\\nüìÇ Loading structured data...\")\n",
        "    if os.path.exists(STRUCTURED_DATA_PATH):\n",
        "        print(f\"Found Excel file at: {STRUCTURED_DATA_PATH}\")\n",
        "        try:\n",
        "            df = pd.read_excel(STRUCTURED_DATA_PATH)\n",
        "            records = df.to_dict('records')\n",
        "            \n",
        "            for record in records:\n",
        "                content = \"\\n\".join(f\"{k}: {v}\" for k, v in record.items())\n",
        "                docs.append(Document(\n",
        "                    page_content=content, \n",
        "                    metadata={\"source\": \"structured_data\"}\n",
        "                ))\n",
        "                \n",
        "            print(f\"    ‚Üí Loaded {len(records)} structured records\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to load Excel: {type(e).__name__}: {str(e)[:100]}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Structured data file not found: {STRUCTURED_DATA_PATH}\")\n",
        "\n",
        "    # 3. Load HTML files\n",
        "    print(\"\\nüìÇ Loading HTML files...\")\n",
        "    for folder in HTML_DIRS:\n",
        "        full_path = os.path.join(DATA_DIR, \"unstructured\", \"web_articles\", folder)\n",
        "        if not os.path.exists(full_path):\n",
        "            print(f\"‚ö†Ô∏è Skipping missing HTML folder: {full_path}\")\n",
        "            continue\n",
        "            \n",
        "        print(f\"\\nProcessing HTML folder: {full_path}\")\n",
        "        html_files = [f for f in os.listdir(full_path) if f.endswith(\".html\")]\n",
        "        \n",
        "        if not html_files:\n",
        "            print(\"  No HTML files found\")\n",
        "            continue\n",
        "            \n",
        "        for file in html_files:\n",
        "            file_path = os.path.join(full_path, file)\n",
        "            try:\n",
        "                print(f\"  Processing: {file[:50]}...\", end=\" \")\n",
        "                with open(file_path, 'rb') as f:\n",
        "                    content = f.read().decode('utf-8', errors='replace')\n",
        "                    if not content.strip():\n",
        "                        print(\"‚ö†Ô∏è Empty, skipping\")\n",
        "                        continue\n",
        "                \n",
        "                loader = TextLoader(file_path, encoding='utf-8')\n",
        "                loaded = loader.load()\n",
        "                docs.extend(loaded)\n",
        "                print(f\"‚úÖ {len(loaded)} chunks\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå {type(e).__name__}: {str(e)[:50]}\")\n",
        "\n",
        "    # 4. Load PDFs\n",
        "    print(\"\\nüìÇ Loading PDFs...\")\n",
        "    for folder in PDF_DIRS:\n",
        "        full_path = os.path.join(DATA_DIR, \"unstructured\", \"pdfs\", folder)\n",
        "        if not os.path.exists(full_path):\n",
        "            print(f\"‚ö†Ô∏è Skipping missing PDF folder: {full_path}\")\n",
        "            continue\n",
        "            \n",
        "        print(f\"\\nProcessing PDF folder: {full_path}\")\n",
        "        pdf_files = [f for f in os.listdir(full_path) if f.endswith(\".pdf\")]\n",
        "        \n",
        "        for file in pdf_files:\n",
        "            file_path = os.path.join(full_path, file)\n",
        "            try:\n",
        "                print(f\"  Processing: {file[:50]}...\", end=\" \")\n",
        "                loader = PyPDFLoader(file_path)\n",
        "                loaded = loader.load()\n",
        "                docs.extend(loaded)\n",
        "                print(f\"‚úÖ {len(loaded)} chunks\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå {str(e)[:50]}\")\n",
        "\n",
        "    print(f\"\\nüìä Total documents loaded: {len(docs)}\")\n",
        "    return docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# --- Split Text ---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_documents(documents):\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    return splitter.split_documents(documents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# --- Build or Load FAISS Vector Store ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_vectorstore(docs):\n",
        "    print(\"\\nüîß Building vector store...\")\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "        model_kwargs={\"device\": \"cpu\"},\n",
        "        encode_kwargs={\"normalize_embeddings\": True}\n",
        "    )\n",
        "    \n",
        "    print(\"‚öôÔ∏è Splitting documents...\")\n",
        "    split_docs = split_documents(docs)\n",
        "    print(f\"üìê Processing {len(split_docs)} document chunks...\") \n",
        "    \n",
        "    print(\"üîÑ Generating embeddings (this may take several minutes)...\")\n",
        "    vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
        "    \n",
        "    print(\"üíæ Saving vector store...\")\n",
        "    os.makedirs(VECTOR_DB_PATH, exist_ok=True)\n",
        "    vectorstore.save_local(VECTOR_DB_PATH)\n",
        "    print(\"‚úÖ Vector store built successfully\")\n",
        "    return vectorstore\n",
        "\n",
        "def load_vectorstore():\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "        model_kwargs={\"device\": \"cpu\"},\n",
        "        encode_kwargs={\"normalize_embeddings\": True}\n",
        "    )\n",
        "    return FAISS.load_local(VECTOR_DB_PATH, embeddings, allow_dangerous_deserialization=True)\n",
        "# Load Structured Data \n",
        "def load_breed_data():\n",
        "    return pd.read_excel(STRUCTURED_DATA_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# --- Prompt ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Internal cache\n",
        "_llm = None\n",
        "\n",
        "def get_llm():\n",
        "    global _llm\n",
        "    if _llm is None:\n",
        "        try:\n",
        "            _llm = pipeline(\n",
        "                \"text-generation\",\n",
        "                model=\"google/gemma-3-4b-it\",\n",
        "                device=\"cpu\",\n",
        "                model_kwargs={\"torch_dtype\": \"auto\"}\n",
        "            )\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"‚ùå Failed to load Gemma: {str(e)}\") from e\n",
        "    return _llm\n",
        "def generate_breed_recommendations(breed_info, vectorstore):\n",
        "    \"\"\"\n",
        "    Generates recommendations in the exact 3-part format for mobile apps\n",
        "    \"\"\"\n",
        "    llm = get_llm()\n",
        "    \n",
        "    # Part 1: Breed Description\n",
        "    description_prompt = f\"\"\"Write a 3-sentence description of {breed_info['Breed Name']} dogs:\n",
        "    - First sentence: Personality traits\n",
        "    - Second sentence: Activity preferences\n",
        "    - Third sentence: Companionship qualities\n",
        "    Example for Golden Retrievers:\n",
        "    \\\"Golden Retrievers are friendly, intelligent companions. They love outdoor adventures! Their gentle nature makes them great family pets.\\\"\n",
        "    Your response:\"\"\"\n",
        "    \n",
        "    description = llm(\n",
        "        description_prompt,\n",
        "        max_new_tokens=100,\n",
        "        temperature=0.7\n",
        "    )[0]['generated_text'].split(\"Your response:\")[-1].strip().strip('\"')\n",
        "    \n",
        "# Part 2: Health Tips - More robust generation\n",
        "    tips_prompt = f\"\"\"Provide 5 essential health tips for {breed_info['Breed Name']} regarding {breed_info['Primary Health Issue']}:\n",
        "    - Format: [emoji] [imperative sentence]!\n",
        "    - Required emojis: ‚ö° ü•ó üèÉ üßº üë©‚Äç‚öïÔ∏è\n",
        "    - Max 12 words per tip\n",
        "    Example:\n",
        "    ‚ö° Active dogs need joint supplements!\n",
        "    ü•ó Measure food to prevent obesity!\n",
        "    üèÉ Daily walks are essential!\n",
        "    üßº Clean ears weekly!\n",
        "    üë©‚Äç‚öïÔ∏è Annual vet checks catch issues early!\n",
        "    Tips:\"\"\"\n",
        "    \n",
        "    # Generate multiple times if needed to get all 5 tips\n",
        "    tips = []\n",
        "    attempts = 0\n",
        "    while len(tips) < 5 and attempts < 3:\n",
        "        tips_response = llm(\n",
        "            tips_prompt,\n",
        "            max_new_tokens=150,\n",
        "            temperature=0.5\n",
        "        )[0]['generated_text']\n",
        "        \n",
        "        # Extract only valid tips\n",
        "        new_tips = [tip.strip() for tip in tips_response.split(\"\\n\") \n",
        "                   if any(tip.strip().startswith(e) for e in [\"‚ö°\", \"ü•ó\", \"üèÉ\", \"üßº\", \"üë©‚Äç‚öïÔ∏è\"])]\n",
        "        tips.extend(new_tips)\n",
        "        attempts += 1\n",
        "    \n",
        "    # Ensure we have exactly 5 unique tips\n",
        "    tips = list(dict.fromkeys(tips))[:5]  # Remove duplicates while preserving order\n",
        "    if len(tips) < 5:\n",
        "        # Fallback tips if generation fails\n",
        "        tips = [\n",
        "            \"‚ö° Regular exercise prevents joint issues!\",\n",
        "            \"ü•ó Feed measured meals to maintain weight!\",\n",
        "            \"üèÉ Daily walks keep your dog healthy!\",\n",
        "            \"üßº Groom weekly to prevent skin problems!\",\n",
        "            \"üë©‚Äç‚öïÔ∏è Annual vet visits catch issues early!\"\n",
        "        ]\n",
        "    \n",
        "    # Part 3: Fun Fact - FIXED VERSION\n",
        "    fact_prompt = f\"\"\"Generate exactly one fun fact about {breed_info['Breed Name']} dogs that would surprise owners:\n",
        "    - Must begin with \"Did you know?\"\n",
        "    - Must end with exactly one relevant emoji\n",
        "    - Must be exactly 1 sentence (10-15 words)\n",
        "    - Must be verifiably true\n",
        "    \n",
        "    Bad Example: \"Fun fact about Beagles...\" (doesn't start correctly)\n",
        "    Bad Example: \"Did you know? Beagles are dogs\" (not surprising)\n",
        "    Good Example: \"Did you know? Beagles can detect smells 10,000x better than humans! üëÉ\"\n",
        "    \n",
        "    Generate now: Did you know?\"\"\"\n",
        "    \n",
        "    # Generate with higher tokens and temperature for creativity\n",
        "    fact_response = llm(\n",
        "        fact_prompt,\n",
        "        max_new_tokens=100,\n",
        "        temperature=1.0,  # Higher for more creative facts\n",
        "        top_p=0.95,\n",
        "        do_sample=True\n",
        "    )[0]['generated_text']\n",
        "    \n",
        "    # Robust extraction and formatting\n",
        "    fact = \"\"\n",
        "    if \"Did you know?\" in fact_response:\n",
        "        fact = fact_response.split(\"Did you know?\")[-1].strip()\n",
        "        # Ensure it ends with emoji\n",
        "        if not any(c in fact for c in [\"üêï\", \"üê∂\", \"üëÉ\", \"üèÉ\", \"üêæ\", \"üåü\", \"!\", \"?\"]):\n",
        "            fact = f\"{fact} üê∂\"\n",
        "        # Ensure proper punctuation\n",
        "        if not fact.endswith((\"!\", \"?\", \".\")):\n",
        "            fact = f\"{fact}!\"\n",
        "    else:\n",
        "        # Fallback fact\n",
        "        fact = f\"Did you know? {breed_info['Breed Name']}s have an extraordinary sense of smell! üëÉ\"\n",
        "    \n",
        "    # Final cleanup\n",
        "    fact = fact.replace('\"', '').strip()\n",
        "    if not fact.startswith(\"Did you know?\"):\n",
        "        fact = f\"Did you know? {fact}\"\n",
        "    \n",
        "    return {\n",
        "        \"description\": description,  # From Part 1\n",
        "        \"tips\": tips,  # From Part 2\n",
        "        \"fun_fact\": fact\n",
        "    }\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# --- Generate AI Advice ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def retrieve_context(query, vectorstore):\n",
        "    docs = vectorstore.similarity_search(query, k=3)\n",
        "    return \"\\n\".join([d.page_content[:500] for d in docs])\n",
        "\n",
        "def generate_advice(breed_info, vectorstore):\n",
        "    print(\"\\nü§ñ Generating advice...\")\n",
        "    llm = get_llm()\n",
        "    \n",
        "    query = f\"{breed_info['Primary Health Issue']} in {breed_info['Breed Name']}\"\n",
        "    context = retrieve_context(query, vectorstore)\n",
        "    \n",
        "    prompt =  generate_breed_recommendations(breed_info, context)\n",
        "    \n",
        "    try:\n",
        "        response = llm(\n",
        "            prompt,\n",
        "            max_new_tokens=600,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            truncation=True\n",
        "        )\n",
        "        \n",
        "        full_response = response[0]['generated_text']\n",
        "        advice_start = full_response.find(\"### Your Advice\") + len(\"### Your Advice\")\n",
        "        advice = full_response[advice_start:].strip()\n",
        "        advice = advice.split(\"###\")[0].strip()\n",
        "        advice = advice.split(\"\\n\\n\")[0].strip()\n",
        "        \n",
        "        if not advice.startswith(breed_info['Breed Name']):\n",
        "            advice = f\"{breed_info['Breed Name']} {advice}\"\n",
        "            \n",
        "        return advice\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error generating advice: {e}\")\n",
        "        return f\"Professional advice for {breed_info['Breed Name']} could not be generated.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# --- Main Entry Point ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "> Starting RAG pipeline :) \n",
            "\n",
            "[Document Loading Progress]\n",
            "\n",
            "üîç Verifying directory structure...\n",
            "‚úì All PDFs directories present\n",
            "‚úì All HTML directories present\n",
            "‚úì All Structured directories present\n",
            "\n",
            "üìÇ Loading structured data...\n",
            "Found Excel file at: rag_data\\structured\\breed_health_data.xlsx\n",
            "    ‚Üí Loaded 208 structured records\n",
            "\n",
            "üìÇ Loading HTML files...\n",
            "\n",
            "Processing HTML folder: rag_data\\unstructured\\web_articles\\kennel_clubs\n",
            "  Processing: A new direction for kennel club regulations and br... ‚úÖ 1 chunks\n",
            "  Processing: AKC's Guide to Responsible Dog Breeding ‚Äì American... ‚úÖ 1 chunks\n",
            "  Processing: Cognitive Traits Vary by Breed - But How and Why_.... ‚úÖ 1 chunks\n",
            "  Processing: Kennel Club Launching Breed Health And Conservatio... ‚úÖ 1 chunks\n",
            "  Processing: The Kennel Club gives first preview of new health ... ‚úÖ 1 chunks\n",
            "  Processing: The Kennel Club Health Standard _ Kennel Club.html... ‚úÖ 1 chunks\n",
            "\n",
            "Processing HTML folder: rag_data\\unstructured\\web_articles\\vet_associations\n",
            "  Processing: Animal & Veterinary _ FDA.html... ‚úÖ 1 chunks\n",
            "  Processing: Animal Help Now - Emergency Resource.html... ‚úÖ 1 chunks\n",
            "  Processing: Benefits of Membership_ American Animal Hospital A... ‚úÖ 1 chunks\n",
            "  Processing: eClinPath _ A Resource for Veterinary Clinical Pat... ‚úÖ 1 chunks\n",
            "  Processing: Home _ ASPCApro.html... ‚úÖ 1 chunks\n",
            "  Processing: Merck Veterinary Manual.html... ‚úÖ 1 chunks\n",
            "  Processing: Pet Health Network _ Pet Health Network¬Æ is dedica... ‚úÖ 1 chunks\n",
            "\n",
            "Processing HTML folder: rag_data\\unstructured\\web_articles\\breeder_forums\n",
            "  Processing: Veterinary Clinical Trials Registry _ Studypages -... ‚úÖ 1 chunks\n",
            "\n",
            "üìÇ Loading PDFs...\n",
            "\n",
            "Processing PDF folder: rag_data\\unstructured\\pdfs\\research_papers\n",
            "  Processing: Experimental infection of domestic dogs and cats.p... ‚úÖ 7 chunks\n",
            "  Processing: FEDIAF-Nutritional-Guidelines_2024.pdf... ‚úÖ 98 chunks\n",
            "  Processing: JOURNAL OF NUTRITIONAL SCIENCE.pdf... ‚úÖ 5 chunks\n",
            "  Processing: Plant-based-Diets-for-Dogs.pdf... ‚úÖ 4 chunks\n",
            "\n",
            "Processing PDF folder: rag_data\\unstructured\\pdfs\\clinical_studies\n",
            "  Processing: 2023-aaha-management-of-allergic-skin-diseases-gui... ‚úÖ 30 chunks\n",
            "  Processing: diagnosis-and-treatment-of-demodicosis-in-dogs-and... ‚úÖ 25 chunks\n",
            "  Processing: Qualityofreportingofclinicaltrialsindogsandcats.pd... ‚úÖ 15 chunks\n",
            "  Processing: understanding-joint-disorders-causes-symptoms-and-... ‚úÖ 4 chunks\n",
            "\n",
            "Processing PDF folder: rag_data\\unstructured\\pdfs\\fda_reports\n",
            "  Processing: 2010-Summary-Report-on-Antimicrobials-Sold-or-Dist... ‚úÖ 27 chunks\n",
            "  Processing: 2019-Annual-Summary.pdf... ‚úÖ 49 chunks\n",
            "  Processing: 3a-role-usp-monographs-cvm-perspective-2014-02-19.... ‚úÖ 22 chunks\n",
            "  Processing: Chapter-5--Center-for-Veterinary-Medicine-(CVM).pd... ‚úÖ 15 chunks\n",
            "\n",
            "üìä Total documents loaded: 523\n",
            "\n",
            "üîß Building vector store...\n",
            "‚öôÔ∏è Splitting documents...\n",
            "üìê Processing 19855 document chunks...\n",
            "üîÑ Generating embeddings (this may take several minutes)...\n",
            "üíæ Saving vector store...\n",
            "‚úÖ Vector store built successfully\n",
            "\n",
            "ü§ñ Generating advice...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36e50d187aa64cfa8fc27550546723a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error generating advice: can only concatenate str (not \"dict\") to str\n",
            "\n",
            ">> Generated Advice:\n",
            "\n",
            "Professional advice for Beagle could not be generated.\n",
            "\n",
            ">> Mobile App Recommendations:\n",
            "\n",
            "# Know More About Me\n",
            "\n",
            "Beagle üåüÔ∏è\n",
            "\n",
            "Beagles are known for their happy-go-lucky and curious personalities. They thrive on sniffing and exploring, requiring plenty of exercise. Beagles make wonderful, loyal companions, always eager to be by their owner's side. üåüÔ∏è\n",
            "\n",
            "## Tips & Recommendations üåüÔ∏è\n",
            "\n",
            "‚ö° Active dogs need joint supplements!\n",
            "ü•ó Measure food to prevent obesity!\n",
            "üèÉ Daily walks are essential!\n",
            "üßº Clean ears weekly!\n",
            "üë©‚Äç‚öïÔ∏è Annual vet checks catch issues early!\n",
            "\n",
            "---\n",
            "\n",
            "### Fun Fact üåüÔ∏è\n",
            "\n",
            "Did you know? Beagles' incredible noses allow them to find hidden bones easily ü¶¥. üê∂! üåüÔ∏è\n",
            "\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n> Starting RAG pipeline :) \")\n",
        "    \n",
        "    if os.path.exists(VECTOR_DB_PATH):\n",
        "        shutil.rmtree(VECTOR_DB_PATH)\n",
        "    \n",
        "    docs = load_documents()\n",
        "    if not docs:\n",
        "        raise ValueError(\"No documents loaded - check your data paths\")\n",
        "    \n",
        "    vectorstore = build_vectorstore(docs)\n",
        "    \n",
        "    try:\n",
        "        df = pd.read_excel(STRUCTURED_DATA_PATH)\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Error loading breed data: {e}\")\n",
        "\n",
        "    breed_name = input(\"Enter breed name: \").strip()\n",
        "    breed_row = df[df[\"Breed Name\"] == breed_name]\n",
        "    \n",
        "    if breed_row.empty:\n",
        "        print(f\"Breed '{breed_name}' not found\")\n",
        "    else:\n",
        "        breed_info = breed_row.iloc[0].to_dict()\n",
        "        \n",
        "        # Generate both detailed advice and mobile recommendations\n",
        "        advice = generate_advice(breed_info, vectorstore)\n",
        "        recommendations = generate_breed_recommendations(breed_info, vectorstore)\n",
        "        \n",
        "        print(\"\\n>> Generated Advice:\\n\")\n",
        "        print(advice)\n",
        "        \n",
        "        print(\"\\n>> Mobile App Recommendations:\\n\")\n",
        "        print(f\"# Know More About Me\\n\")\n",
        "        print(f\"{breed_info['Breed Name']} üåüÔ∏è\\n\")\n",
        "        print(f\"{recommendations['description']} üåüÔ∏è\\n\")\n",
        "        print(\"## Tips & Recommendations üåüÔ∏è\\n\")\n",
        "        print(\"\\n\".join(recommendations['tips']))\n",
        "        print(\"\\n---\\n\")\n",
        "        print(f\"### Fun Fact üåüÔ∏è\\n\")\n",
        "        print(f\"{recommendations['fun_fact']} üåüÔ∏è\\n\")\n",
        "        print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
